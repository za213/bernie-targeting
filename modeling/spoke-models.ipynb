{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "import civis\n",
    "import civis.io\n",
    "from civis.futures import CivisFuture\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from civis.ml import ModelPipeline\n",
    "from muffnn import MLPClassifier, MLPRegressor\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "import math\n",
    "from pprint import pprint\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "DATABASE = 'Bernie 2020'\n",
    "PRIMARY_KEY = 'person_id'\n",
    "DV_TABLE = 'modeling.spoke_dvs'\n",
    "\n",
    "DV_LIST = ['spoke_support_1box','spoke_persuasion_1plus','spoke_persuasion_2plus']\n",
    "\n",
    "MODELING_FRAME = 'bernie_data_commons.phoenix_modeling_frame'\n",
    "EXCLUSION_COLUMNS = ['jsonid']\n",
    "\n",
    "SCHEMA = 'bernie_nmarchio2'\n",
    "PREFIX = 'scored'\n",
    "\n",
    "datestamp = '{:%Y%m%d}'.format(datetime.date.today())\n",
    "score_table = f'{SCHEMA}.{PREFIX}_output_{datestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count classes and undersample to avoid class imbalance problems\n",
    "dv_sql_sum = \"\\n\".join([\",sum({dv}) as {dv}\".format(dv=i) for i in DV_LIST])\n",
    "sql_collapse = f\"\"\"select count(*) {dv_sql_sum} from {DV_TABLE};\"\"\"\n",
    "sql_count = civis.io.read_civis_sql(sql_collapse, DATABASE)\n",
    "\n",
    "undersample_list = []\n",
    "for i in (sql_count[1][1:]):\n",
    "    u = (int(i)*2)\n",
    "    undersample_list.append(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP VIEW IF EXISTS bernie_nmarchio2.spoke_training_2 CASCADE;\n",
      "    CREATE VIEW bernie_nmarchio2.spoke_training_2 AS \n",
      "    (select * from (\n",
      "    (select person_id, spoke_persuasion_2plus from modeling.spoke_dvs where spoke_persuasion_2plus = 1) \n",
      "    union all \n",
      "    (select person_id, spoke_persuasion_2plus from modeling.spoke_dvs where spoke_persuasion_2plus = 0 and random() < 0.01084))\n",
      "    left join bernie_data_commons.phoenix_modeling_frame using(person_id));\n",
      "DROP VIEW IF EXISTS bernie_nmarchio2.spoke_training_2 CASCADE;\n",
      "    CREATE VIEW bernie_nmarchio2.spoke_training_2 AS \n",
      "    (select * from (\n",
      "    (select person_id, spoke_persuasion_2plus from modeling.spoke_dvs where spoke_persuasion_2plus = 1) \n",
      "    union all \n",
      "    (select person_id, spoke_persuasion_2plus from modeling.spoke_dvs where spoke_persuasion_2plus = 0 and random() < 0.01084))\n",
      "    left join bernie_data_commons.phoenix_modeling_frame using(person_id));\n",
      "DROP VIEW IF EXISTS bernie_nmarchio2.spoke_training_2 CASCADE;\n",
      "    CREATE VIEW bernie_nmarchio2.spoke_training_2 AS \n",
      "    (select * from (\n",
      "    (select person_id, spoke_persuasion_2plus from modeling.spoke_dvs where spoke_persuasion_2plus = 1) \n",
      "    union all \n",
      "    (select person_id, spoke_persuasion_2plus from modeling.spoke_dvs where spoke_persuasion_2plus = 0 and random() < 0.01084))\n",
      "    left join bernie_data_commons.phoenix_modeling_frame using(person_id));\n"
     ]
    }
   ],
   "source": [
    "# Create training views\n",
    "for i in range(len(sql_count[1])-1):\n",
    "    dv_item = DV_LIST[i]\n",
    "    random_sample = round(int(undersample_list[i])/int(sql_count[1][0]),5)\n",
    "    training_sql = f\"\"\"DROP VIEW IF EXISTS {SCHEMA}.{PREFIX}_training_{i} CASCADE;\n",
    "    CREATE VIEW {SCHEMA}.{PREFIX}_training_{i} AS \n",
    "    (select * from (\n",
    "    (select {PRIMARY_KEY}, {dv_item} from {DV_TABLE} where {dv_item} = 1) \n",
    "    union all \n",
    "    (select {PRIMARY_KEY}, {dv_item} from {DV_TABLE} where {dv_item} = 0 and random() < {random_sample}))\n",
    "    left join {MODELING_FRAME} using({PRIMARY_KEY}));\"\"\"\n",
    "    print(q)\n",
    "    create_training_sql = civis.io.query_civis(training_sql, database=DATABASE)\n",
    "    create_training_sql.result().state\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING >>> spoke_support_1box\n",
      "TRAINING >>> spoke_persuasion_1plus\n",
      "TRAINING >>> spoke_persuasion_2plus\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "train_list = []\n",
    "model_list = []\n",
    "\n",
    "for index, dv in enumerate(DV_LIST):\n",
    "    print('TRAINING >>> {}'.format(dv))\n",
    "    \n",
    "    exc_list = DV_LIST.copy()\n",
    "    exc_list.remove(dv)\n",
    "    \n",
    "    assert dv not in exc_list \n",
    "    \n",
    "    name = f\"\"\"{dv}_{datestamp}\"\"\"\n",
    "    model = ModelPipeline(model='sparse_logistic',\n",
    "                          dependent_variable=dv,\n",
    "                          primary_key=PRIMARY_KEY,\n",
    "                          excluded_columns=EXCLUSION_COLUMNS,\n",
    "                          calibration='sigmoid',\n",
    "                          model_name=name,\n",
    "                          memory_requested=12000)\n",
    "    \n",
    "    where_sql = '{} is not null'.format(dv)\n",
    "\n",
    "    train = model.train(table_name=f\"\"\"{SCHEMA}.{PREFIX}_training_{index}\"\"\", \n",
    "                        database_name=DATABASE,\n",
    "                        sql_where=where_sql#,\n",
    "                        #fit_params={'sample_weight': WEIGHT_COL}\n",
    "                       )\n",
    "    \n",
    "    model_list.append(model)\n",
    "    train_list.append(train)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job success\n",
      "job success\n",
      "job success\n"
     ]
    }
   ],
   "source": [
    "# Get output of successful models\n",
    "model_output = model_list\n",
    "train_output = train_list\n",
    "\n",
    "jobs_list = []\n",
    "for t in train_output: \n",
    "    try:\n",
    "        if len(t.metadata['output']) > 0:  \n",
    "            jobs_list.append(t)\n",
    "            print('Job success')\n",
    "    except:\n",
    "        print('Job failure)\n",
    "        pass\n",
    "\n",
    "model_output, train_ouput = zip(*((model, train) for model, train in zip(model_output, train_output) if train in jobs_list))\n",
    "model_output = list(model_output)\n",
    "train_output = list(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>dv</th>\n",
       "      <th>model</th>\n",
       "      <th>time_of_train_run</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_features</th>\n",
       "      <th>auc</th>\n",
       "      <th>deciles</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>p_correct</th>\n",
       "      <th>pop_incidence_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189178440</th>\n",
       "      <td>51800037</td>\n",
       "      <td>spoke_support_1box</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-09T04:28:52Z</td>\n",
       "      <td>123095</td>\n",
       "      <td>44</td>\n",
       "      <td>0.723725</td>\n",
       "      <td>[0.12412672623883023, 0.1966041108132261, 0.24...</td>\n",
       "      <td>[[56442, 15610], [24461, 26582]]</td>\n",
       "      <td>0.674471</td>\n",
       "      <td>[0.7833509132293344, 0.5207766001214662]</td>\n",
       "      <td>[0.5853365286973475, 0.4146634713026524]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189178442</th>\n",
       "      <td>51800039</td>\n",
       "      <td>spoke_persuasion_1plus</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-09T04:29:48Z</td>\n",
       "      <td>8293</td>\n",
       "      <td>44</td>\n",
       "      <td>0.562693</td>\n",
       "      <td>[0.24125452352231605, 0.26867469879518074, 0.3...</td>\n",
       "      <td>[[5486, 15], [2779, 13]]</td>\n",
       "      <td>0.663089</td>\n",
       "      <td>[0.9972732230503545, 0.004656160458452722]</td>\n",
       "      <td>[0.6633305197154227, 0.3366694802845773]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189178445</th>\n",
       "      <td>51800042</td>\n",
       "      <td>spoke_persuasion_2plus</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-09T04:29:14Z</td>\n",
       "      <td>2895</td>\n",
       "      <td>44</td>\n",
       "      <td>0.560332</td>\n",
       "      <td>[0.30689655172413793, 0.27335640138408307, 0.2...</td>\n",
       "      <td>[[1938, 9], [946, 2]]</td>\n",
       "      <td>0.670121</td>\n",
       "      <td>[0.9953775038520801, 0.002109704641350211]</td>\n",
       "      <td>[0.672538860103627, 0.32746113989637304]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id                      dv            model  \\\n",
       "run_id                                                         \n",
       "189178440  51800037      spoke_support_1box  sparse_logistic   \n",
       "189178442  51800039  spoke_persuasion_1plus  sparse_logistic   \n",
       "189178445  51800042  spoke_persuasion_2plus  sparse_logistic   \n",
       "\n",
       "              time_of_train_run  n_rows  n_features       auc  \\\n",
       "run_id                                                          \n",
       "189178440  2019-12-09T04:28:52Z  123095          44  0.723725   \n",
       "189178442  2019-12-09T04:29:48Z    8293          44  0.562693   \n",
       "189178445  2019-12-09T04:29:14Z    2895          44  0.560332   \n",
       "\n",
       "                                                     deciles  \\\n",
       "run_id                                                         \n",
       "189178440  [0.12412672623883023, 0.1966041108132261, 0.24...   \n",
       "189178442  [0.24125452352231605, 0.26867469879518074, 0.3...   \n",
       "189178445  [0.30689655172413793, 0.27335640138408307, 0.2...   \n",
       "\n",
       "                           confusion_matrix  accuracy  \\\n",
       "run_id                                                  \n",
       "189178440  [[56442, 15610], [24461, 26582]]  0.674471   \n",
       "189178442          [[5486, 15], [2779, 13]]  0.663089   \n",
       "189178445             [[1938, 9], [946, 2]]  0.670121   \n",
       "\n",
       "                                            p_correct  \\\n",
       "run_id                                                  \n",
       "189178440    [0.7833509132293344, 0.5207766001214662]   \n",
       "189178442  [0.9972732230503545, 0.004656160458452722]   \n",
       "189178445  [0.9953775038520801, 0.002109704641350211]   \n",
       "\n",
       "                                 pop_incidence_true  \n",
       "run_id                                               \n",
       "189178440  [0.5853365286973475, 0.4146634713026524]  \n",
       "189178442  [0.6633305197154227, 0.3366694802845773]  \n",
       "189178445  [0.672538860103627, 0.32746113989637304]  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate validation metrics\n",
    "metrics_list = []\n",
    "\n",
    "for a, b in enumerate(train_output):\n",
    "    metric = {'job_id':b.job_id,\n",
    "              'run_id':b.run_id,\n",
    "              'dv': ''.join(b.metadata['run']['configuration']['data']['y']),\n",
    "              'model': b.metadata['model']['model'],\n",
    "              'time_of_train_run': b.metadata['run']['time_of_run'],\n",
    "              'n_rows': b.metadata['data']['n_rows'],\n",
    "              'n_features': b.metadata['data']['n_cols'],\n",
    "              'auc': b.metadata['metrics']['roc_auc'],\n",
    "              'deciles': b.metadata['metrics']['deciles'],\n",
    "              'confusion_matrix': b.metadata['metrics']['confusion_matrix'],\n",
    "              'accuracy': b.metadata['metrics']['accuracy'],\n",
    "              'p_correct': b.metadata['metrics']['p_correct'],\n",
    "              'pop_incidence_true': b.metadata['metrics']['pop_incidence_true']\n",
    "             }\n",
    "    metrics_list.append(metric)\n",
    "    \n",
    "metric_order = (['job_id', 'run_id', 'dv', 'model', 'time_of_train_run', 'n_rows', 'n_features',\n",
    "                 'auc', 'deciles', 'confusion_matrix', 'accuracy', 'p_correct','pop_incidence_true'])\n",
    "\n",
    "validation_df = pd.DataFrame.from_records(metrics_list, columns=metric_order, index='run_id')\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write validation metrics to Redshift\n",
    "create_validation_table = civis.io.dataframe_to_civis(df=validation_df,\n",
    "                                                 database=DATABASE, \n",
    "                                                 table= f'{SCHEMA}.{PREFIX}_validation_{datestamp}', \n",
    "                                                 existing_table_rows='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spoke_support_1box\n",
      "spoke_persuasion_1plus\n",
      "spoke_persuasion_2plus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the voterfile\n",
    "scores_list = []\n",
    "for m,t in zip(model_output, train_output):\n",
    "    DV_LABEL = ''.join(t.metadata['run']['configuration']['data']['y'])\n",
    "    print(DV_LABEL)\n",
    "    SCORES_TABLE = f'{SCHEMA}.{PREFIX}_{DV_LABEL}_{datestamp}'\n",
    "    scores_list.append(SCORES_TABLE)\n",
    "    scores = m.predict(primary_key=PRIMARY_KEY,\n",
    "                       database_name=DATABASE, \n",
    "                       table_name=MODELING_FRAME,\n",
    "                       if_exists='drop',\n",
    "                       output_table=SCORES_TABLE,\n",
    "                       disk_space=20)\n",
    "scores.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant team on tables\n",
    "grant_sql = \"\".join([\"GRANT SELECT ON {tbl} TO GROUP bernie_data;\".format(tbl=i) for i in scores_list])\n",
    "grant_statement = f\"\"\"\n",
    "GRANT ALL ON SCHEMA {SCHEMA} TO GROUP bernie_data;\n",
    "{grant_sql}\n",
    "\"\"\"\n",
    "grant_team = civis.io.query_civis(sql=grant_statement, database=DATABASE)\n",
    "grant_team.result().state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop training views\n",
    "\n",
    "drop_statement = []\n",
    "for i in range(len(sql_count[1])-1):\n",
    "    drop_sql = f\"{SCHEMA}.{PREFIX}_training_{i} CASCADE;\"\n",
    "    drop_statement.append(drop_sql)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_training_views = f'''\n",
    "DROP VIEW IF EXISTS {} CASCADE;'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
