{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "import civis\n",
    "import civis.io\n",
    "from civis.futures import CivisFuture\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from civis.ml import ModelPipeline\n",
    "from muffnn import MLPClassifier, MLPRegressor\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "import math\n",
    "from pprint import pprint\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameter\n",
    "DATABASE = 'Bernie 2020'\n",
    "PRIMARY_KEY = 'person_id'\n",
    "DV_TABLE = 'bernie_nmarchio2.spoke_dvs'\n",
    "\n",
    "DV_LIST = ['spoke_support_1box', 'spoke_persuasion_1plus', 'spoke_persuasion_1minus']\n",
    "\n",
    "MODELING_FRAME = 'bernie_data_commons.phoenix_modeling_frame'\n",
    "EXCLUSION_COLUMNS = ['jsonid']\n",
    "\n",
    "SCHEMA = 'bernie_nmarchio2'\n",
    "PREFIX = 'scored'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp = '{:%Y%m%d}'.format(datetime.date.today())\n",
    "score_table = f'{SCHEMA}.{PREFIX}_output_{datestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count positive and negative classes\n",
    "dv_sql_targets = \"\\n,\".join([\"sum({dv}) as {dv}\".format(dv=i) for i in DV_LIST])\n",
    "sql_collapse_targets = f\"\"\"select {dv_sql_targets} from {DV_TABLE};\"\"\"\n",
    "sql_count_targets = civis.io.read_civis_sql(sql_collapse_targets, DATABASE)\n",
    "\n",
    "dv_sql_zeroes = \"\\n,\".join([\"sum(case when {dv} = 0 then 1 end) as {dv}\".format(dv=i) for i in DV_LIST])\n",
    "sql_collapse_zeroes = f\"\"\"select {dv_sql_zeroes} from {DV_TABLE};\"\"\"\n",
    "sql_count_zeroes = civis.io.read_civis_sql(sql_collapse_zeroes, DATABASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Share of negatives to sample based on number of positives (to avoid class imbalance problems)\n",
    "sample_share = []\n",
    "for i in range(len(DV_LIST)):\n",
    "    u = round((int(sql_count_targets[1][i])*2)/(int(sql_count_zeroes[1][i])),5)\n",
    "    sample_share.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training views\n",
    "for i in range(len(DV_LIST)):\n",
    "    dv_item = DV_LIST[i]\n",
    "    random_sample = sample_share[i]\n",
    "    training_sql = f\"\"\"DROP VIEW IF EXISTS {SCHEMA}.{PREFIX}_training_{i} CASCADE;\n",
    "    CREATE VIEW {SCHEMA}.{PREFIX}_training_{i} AS \n",
    "    (select * from (\n",
    "    (select {PRIMARY_KEY}, {dv_item} from {DV_TABLE} where {dv_item} = 1) \n",
    "    union all \n",
    "    (select {PRIMARY_KEY}, {dv_item} from {DV_TABLE} where {dv_item} = 0 and random() < {random_sample}))\n",
    "    left join {MODELING_FRAME} using({PRIMARY_KEY}));\"\"\"\n",
    "    create_training_sql = civis.io.query_civis(training_sql, database=DATABASE)\n",
    "    create_training_sql.result().state\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING >>> spoke_support_1box\n",
      "TRAINING >>> spoke_persuasion_1plus\n",
      "TRAINING >>> spoke_persuasion_1minus\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "train_list = []\n",
    "model_list = []\n",
    "\n",
    "for index, dv in enumerate(DV_LIST):\n",
    "    print('TRAINING >>> {}'.format(dv))\n",
    "    \n",
    "    exc_list = DV_LIST.copy()\n",
    "    exc_list.remove(dv)\n",
    "    \n",
    "    assert dv not in exc_list \n",
    "    \n",
    "    name = f\"\"\"{dv}_{datestamp}\"\"\"\n",
    "    model = ModelPipeline(model='sparse_logistic',\n",
    "                          dependent_variable=dv,\n",
    "                          primary_key=PRIMARY_KEY,\n",
    "                          excluded_columns=EXCLUSION_COLUMNS,\n",
    "                          calibration='sigmoid',\n",
    "                          model_name=name,\n",
    "                          memory_requested=12000)\n",
    "    \n",
    "    where_string = '{} is not null'.format(dv)\n",
    "\n",
    "    train = model.train(table_name=f\"\"\"{SCHEMA}.{PREFIX}_training_{index}\"\"\", \n",
    "                        database_name=DATABASE,\n",
    "                        sql_where=where_string#,\n",
    "                        #fit_params={'sample_weight': WEIGHT_VAR}\n",
    "                       )\n",
    "    \n",
    "    model_list.append(model)\n",
    "    train_list.append(train)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job success\n",
      "Job success\n",
      "Job success\n"
     ]
    }
   ],
   "source": [
    "# Get output of successful models\n",
    "model_output = model_list\n",
    "train_output = train_list\n",
    "\n",
    "jobs_list = []\n",
    "for t in train_output: \n",
    "    try:\n",
    "        if len(t.metadata['output']) > 0:  \n",
    "            jobs_list.append(t)\n",
    "            print('Job success')\n",
    "    except:\n",
    "        print('Job failure')\n",
    "        pass\n",
    "\n",
    "model_output, train_ouput = zip(*((model, train) for model, train in zip(model_output, train_output) if train in jobs_list))\n",
    "model_output = list(model_output)\n",
    "train_output = list(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>dv</th>\n",
       "      <th>model</th>\n",
       "      <th>time_of_train_run</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_features</th>\n",
       "      <th>auc</th>\n",
       "      <th>deciles</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>p_correct</th>\n",
       "      <th>pop_incidence_true</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189716219</th>\n",
       "      <td>52069719</td>\n",
       "      <td>spoke_support_1box</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-10T17:08:23Z</td>\n",
       "      <td>155925</td>\n",
       "      <td>44</td>\n",
       "      <td>0.731163</td>\n",
       "      <td>[0.08119548486403284, 0.13486821009427308, 0.1...</td>\n",
       "      <td>[[90571, 13329], [32204, 19821]]</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>[0.8717131857555341, 0.38098990869774146]</td>\n",
       "      <td>[0.6663459996793331, 0.333654000320667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189716240</th>\n",
       "      <td>52069728</td>\n",
       "      <td>spoke_persuasion_1plus</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-10T17:07:49Z</td>\n",
       "      <td>8673</td>\n",
       "      <td>44</td>\n",
       "      <td>0.608623</td>\n",
       "      <td>[0.18223760092272204, 0.23617511520737328, 0.2...</td>\n",
       "      <td>[[5739, 68], [2791, 75]]</td>\n",
       "      <td>0.670356</td>\n",
       "      <td>[0.9882899948338213, 0.026168876482903]</td>\n",
       "      <td>[0.6695491756024443, 0.33045082439755563]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189716247</th>\n",
       "      <td>52069736</td>\n",
       "      <td>spoke_persuasion_1minus</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-10T17:07:48Z</td>\n",
       "      <td>2272</td>\n",
       "      <td>44</td>\n",
       "      <td>0.709138</td>\n",
       "      <td>[0.09251101321585903, 0.15418502202643172, 0.1...</td>\n",
       "      <td>[[1345, 170], [544, 213]]</td>\n",
       "      <td>0.685739</td>\n",
       "      <td>[0.8877887788778878, 0.2813738441215324]</td>\n",
       "      <td>[0.6668133802816901, 0.3331866197183099]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id                       dv            model  \\\n",
       "run_id                                                          \n",
       "189716219  52069719       spoke_support_1box  sparse_logistic   \n",
       "189716240  52069728   spoke_persuasion_1plus  sparse_logistic   \n",
       "189716247  52069736  spoke_persuasion_1minus  sparse_logistic   \n",
       "\n",
       "              time_of_train_run  n_rows  n_features       auc  \\\n",
       "run_id                                                          \n",
       "189716219  2019-12-10T17:08:23Z  155925          44  0.731163   \n",
       "189716240  2019-12-10T17:07:49Z    8673          44  0.608623   \n",
       "189716247  2019-12-10T17:07:48Z    2272          44  0.709138   \n",
       "\n",
       "                                                     deciles  \\\n",
       "run_id                                                         \n",
       "189716219  [0.08119548486403284, 0.13486821009427308, 0.1...   \n",
       "189716240  [0.18223760092272204, 0.23617511520737328, 0.2...   \n",
       "189716247  [0.09251101321585903, 0.15418502202643172, 0.1...   \n",
       "\n",
       "                           confusion_matrix  accuracy  \\\n",
       "run_id                                                  \n",
       "189716219  [[90571, 13329], [32204, 19821]]  0.707981   \n",
       "189716240          [[5739, 68], [2791, 75]]  0.670356   \n",
       "189716247         [[1345, 170], [544, 213]]  0.685739   \n",
       "\n",
       "                                           p_correct  \\\n",
       "run_id                                                 \n",
       "189716219  [0.8717131857555341, 0.38098990869774146]   \n",
       "189716240    [0.9882899948338213, 0.026168876482903]   \n",
       "189716247   [0.8877887788778878, 0.2813738441215324]   \n",
       "\n",
       "                                  pop_incidence_true  \n",
       "run_id                                                \n",
       "189716219    [0.6663459996793331, 0.333654000320667]  \n",
       "189716240  [0.6695491756024443, 0.33045082439755563]  \n",
       "189716247   [0.6668133802816901, 0.3331866197183099]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate validation metrics\n",
    "metrics_list = []\n",
    "\n",
    "for a, b in enumerate(train_output):\n",
    "    metric = {'job_id':b.job_id,\n",
    "              'run_id':b.run_id,\n",
    "              'dv': ''.join(b.metadata['run']['configuration']['data']['y']),\n",
    "              'model': b.metadata['model']['model'],\n",
    "              'time_of_train_run': b.metadata['run']['time_of_run'],\n",
    "              'n_rows': b.metadata['data']['n_rows'],\n",
    "              'n_features': b.metadata['data']['n_cols'],\n",
    "              'auc': b.metadata['metrics']['roc_auc'],\n",
    "              'deciles': b.metadata['metrics']['deciles'],\n",
    "              'confusion_matrix': b.metadata['metrics']['confusion_matrix'],\n",
    "              'accuracy': b.metadata['metrics']['accuracy'],\n",
    "              'p_correct': b.metadata['metrics']['p_correct'],\n",
    "              'pop_incidence_true': b.metadata['metrics']['pop_incidence_true']\n",
    "             }\n",
    "    metrics_list.append(metric)\n",
    "    \n",
    "metric_order = (['job_id', 'run_id', 'dv', 'model', 'time_of_train_run', 'n_rows', 'n_features',\n",
    "                 'auc', 'deciles', 'confusion_matrix', 'accuracy', 'p_correct','pop_incidence_true'])\n",
    "\n",
    "validation_df = pd.DataFrame.from_records(metrics_list, columns=metric_order, index='run_id')\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write validation metrics to Redshift\n",
    "create_validation_table = civis.io.dataframe_to_civis(df=validation_df,\n",
    "                                                 database=DATABASE, \n",
    "                                                 table= f'{SCHEMA}.model_validation_{datestamp}', \n",
    "                                                 existing_table_rows='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spoke_support_1box\n",
      "spoke_persuasion_1plus\n",
      "spoke_persuasion_1minus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'container_id': 52070458,\n",
       " 'error': None,\n",
       " 'finished_at': '2019-12-10T17:30:29.000Z',\n",
       " 'id': 189717357,\n",
       " 'is_cancel_requested': False,\n",
       " 'started_at': '2019-12-10T17:09:35.000Z',\n",
       " 'state': 'succeeded'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the voterfile\n",
    "scores_list = []\n",
    "for m,t in zip(model_output, train_output):\n",
    "    DV_NAME = ''.join(t.metadata['run']['configuration']['data']['y'])\n",
    "    print(DV_NAME)\n",
    "    SCORES_TABLE = f'{SCHEMA}.{PREFIX}_{DV_NAME}_{datestamp}'\n",
    "    scores_list.append(SCORES_TABLE)\n",
    "    scores = m.predict(primary_key=PRIMARY_KEY,\n",
    "                       database_name=DATABASE, \n",
    "                       table_name=MODELING_FRAME,\n",
    "                       if_exists='drop',\n",
    "                       output_table=SCORES_TABLE,\n",
    "                       disk_space=20)\n",
    "scores.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grant team on tables\n",
    "grant_sql = \"\".join([\"GRANT SELECT ON {tbl} TO GROUP bernie_data;\".format(tbl=i) for i in scores_list])\n",
    "grant_statement = f\"\"\"\n",
    "GRANT ALL ON SCHEMA {SCHEMA} TO GROUP bernie_data;\n",
    "{grant_sql}\n",
    "\"\"\"\n",
    "grant_team = civis.io.query_civis(sql=grant_statement, database=DATABASE)\n",
    "grant_team.result().state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop training views\n",
    "drop_statement = []\n",
    "for i in range(len(DV_LIST)):\n",
    "    drop_sql = f\"drop view if exists {SCHEMA}.{PREFIX}_training_{i} CASCADE;\"\n",
    "    drop_statement.append(drop_sql)\n",
    "drop_sql = \"\".join([\"{tbl}\".format(tbl=i) for i in drop_statement])\n",
    "drop_views = civis.io.query_civis(sql=drop_sql, database=DATABASE)\n",
    "drop_views.result().state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join everything together and decile / drop redundant tables and views\n",
    "view_list = []\n",
    "table_list = []\n",
    "for i in range(len(DV_LIST)):\n",
    "    view = f\"{SCHEMA}.{PREFIX}_training_{i}\"\n",
    "    view_list.append(view)\n",
    "    table = f\"{SCHEMA}.{PREFIX}_{DV_LIST[i]}_{datestamp}\"\n",
    "    table_list.append(table)\n",
    "\n",
    "drop_view = \"\".join([\"drop view if exists {view} CASCADE;\".format(view=v) for v in view_list])\n",
    "drop_table = \"\".join([\"drop table if exists {tbl} CASCADE;\".format(tbl=t) for t in table_list])\n",
    "dv_strings = \"\\n,\".join([\"{dv_score}_1 as {dv_score}\".format(dv_score=dv) for dv in DV_LIST])\n",
    "dv_tiles = \"\\n,\".join([\"NTILE(100) OVER (ORDER BY {dv_tile}_1) AS {dv_tile}_100\".format(dv_tile=dv) for dv in DV_LIST])\n",
    "join_table = []\n",
    "if len(table_list) > 1:\n",
    "    for i in table_list[1:]:\n",
    "        j = str(' left join '+f'{i}'+f' using({PRIMARY_KEY}) ')\n",
    "        join_table.append(j)\n",
    "        #dv_strings = \"\\nleft join \".join([\"{dv_score}\".format(table=tbl) for tbl in table_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table = f\"\"\"DROP TABLE IF EXISTS {SCHEMA}.{PREFIX}_output_{datestamp};\n",
    "CREATE TABLE {SCHEMA}.{PREFIX}_output_{datestamp}\n",
    "  DISTSTYLE KEY\n",
    "  DISTKEY ({PRIMARY_KEY})\n",
    "  SORTKEY ({PRIMARY_KEY})\n",
    "  AS (\"\"\"+'select '+ f\"{PRIMARY_KEY} \\n,\" + dv_strings + \"\\n,\" + dv_tiles + ' from '+ ''.join(table_list[0]) + ''.join(join_table) +');'  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS bernie_nmarchio2.scored_output_20191210;\n",
      "CREATE TABLE bernie_nmarchio2.scored_output_20191210\n",
      "  DISTSTYLE KEY\n",
      "  DISTKEY (person_id)\n",
      "  SORTKEY (person_id)\n",
      "  AS (select person_id \n",
      ",spoke_support_1box_1 as spoke_support_1box\n",
      ",spoke_persuasion_1plus_1 as spoke_persuasion_1plus\n",
      ",spoke_persuasion_1minus_1 as spoke_persuasion_1minus\n",
      ",NTILE(100) OVER (ORDER BY spoke_support_1box_1) AS spoke_support_1box_100\n",
      ",NTILE(100) OVER (ORDER BY spoke_persuasion_1plus_1) AS spoke_persuasion_1plus_100\n",
      ",NTILE(100) OVER (ORDER BY spoke_persuasion_1minus_1) AS spoke_persuasion_1minus_100 from bernie_nmarchio2.scored_spoke_support_1box_20191210 left join bernie_nmarchio2.scored_spoke_persuasion_1plus_20191210 using(person_id)  left join bernie_nmarchio2.scored_spoke_persuasion_1minus_20191210 using(person_id) );\n"
     ]
    }
   ],
   "source": [
    "print(output_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    drop_sql = f\"drop view if exists {SCHEMA}.{PREFIX}_training_{i} CASCADE;\"\n",
    "    drop_statement.append(drop_sql)\n",
    "    \n",
    "\n",
    "scored_spoke_persuasion_1minus_20191209\n",
    "scored_spoke_persuasion_1plus_20191209\n",
    "scored_spoke_support_1box_20191209\n",
    "\n",
    "ntiles_sql = \"\\n\".join([\",NTILE(100) OVER (ORDER BY {v_item}) AS {v_item}_100\".format(v_item=k) for k in DV_LIST])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
