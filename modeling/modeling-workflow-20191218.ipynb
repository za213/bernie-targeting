{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import datetime\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize \n",
    "\n",
    "import civis\n",
    "import civis.io\n",
    "from civis.futures import CivisFuture\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, RandomForestRegressor\n",
    "from civis.ml import ModelPipeline\n",
    "\n",
    "import uuid\n",
    "import json\n",
    "from pprint import pprint\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default feature lists for Rainbow Modeling Frame (each number corresponds to number of features)\n",
    "feature_table = civis.io.read_civis_sql(sql='select * from bernie_nmarchio2.feature_list order by sort_order asc', use_pandas = True, database='Bernie 2020')\n",
    "feature_list_large = list(feature_table[(feature_table['frame_large'] == 1)]['feature_name']) + ['state_code']\n",
    "feature_list_medium = list(feature_table[(feature_table['frame_medium'] == 1)]['feature_name']) + ['state_code']\n",
    "feature_list_small = list(feature_table[(feature_table['frame_small'] == 1)]['feature_name']) + ['state_code']\n",
    "\n",
    "table_columns = civis.io.read_civis_sql(\n",
    "    sql=f'''select ordinal_position as position, column_name, data_type \n",
    "    from information_schema.columns \n",
    "    where table_name = 'rainbow_modeling_frame' and table_schema = 'bernie_data_commons' and column_name != 'person_id'\n",
    "    order by ordinal_position;''', use_pandas = True, database='Bernie 2020')\n",
    "\n",
    "#exclusion_list_466 = [e for e in list(table_columns['column_name']) if e not in feature_list_466] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters\n",
    "DATABASE = 'Bernie 2020'\n",
    "\n",
    "# Primary key in both the DV table and the Modeling Frame\n",
    "PRIMARY_KEY = 'person_id'\n",
    "\n",
    "# Table containing recoded Dependent Variables keyed to the PRIMARY_KEY\n",
    "DV_TABLE = 'bernie_nmarchio2.spoke_dvs'\n",
    "# List of binarized dependent variables (accepts 1, 0, and null values) in DV_TABLE\n",
    "DV_LIST = ['spoke_support_1box', 'spoke_persuasion_1plus', 'spoke_persuasion_1minus']\n",
    "\n",
    "\n",
    "# Table containing covariates and keyed to PRIMARY_KEY\n",
    "MODELING_FRAME = 'bernie_data_commons.rainbow_modeling_frame'\n",
    "# Columns in the Modeling Frame to exclude from feature list (i.e., strings or incomplete coverage)\n",
    "EXCLUSION_COLUMNS = ['state_code']\n",
    "\n",
    "# Schema to contain prediction tables\n",
    "SCHEMA = 'bernie_nmarchio2'\n",
    "# String that will be concatenated in front of the output table's name\n",
    "PREFIX = 'scored'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp = '{:%Y%m%d}'.format(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of positive and negative classes\n",
    "dv_sql_targets = \"\\n,\".join([\"sum({dv}) as {dv}\".format(dv=i) for i in DV_LIST])\n",
    "sql_collapse_targets = f\"\"\"select {dv_sql_targets} from {DV_TABLE};\"\"\"\n",
    "sql_count_targets = civis.io.read_civis_sql(sql_collapse_targets, DATABASE)\n",
    "\n",
    "dv_sql_zeroes = \"\\n,\".join([\"sum(case when {dv} = 0 then 1 end) as {dv}\".format(dv=i) for i in DV_LIST])\n",
    "sql_collapse_zeroes = f\"\"\"select {dv_sql_zeroes} from {DV_TABLE};\"\"\"\n",
    "sql_count_zeroes = civis.io.read_civis_sql(sql_collapse_zeroes, DATABASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determing training table proportion of positives to negatives (to avoid class imbalance problems)\n",
    "sample_share = []\n",
    "for i in range(len(DV_LIST)):\n",
    "    u = round((int(sql_count_targets[1][i])*2)/(int(sql_count_zeroes[1][i])),5)\n",
    "    sample_share.append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training views\n",
    "for i in range(len(DV_LIST)):\n",
    "    if (int(sql_count_targets[1][i])*3) <= 1000:\n",
    "        feature_select = \"\\n,\".join([\"{feature}\".format(feature=f) for f in feature_list_small])\n",
    "    if (int(sql_count_targets[1][i])*3) > 1000 & (int(sql_count_targets[1][i])*3) <= 2000:\n",
    "        feature_select = \"\\n,\".join([\"{feature}\".format(feature=f) for f in feature_list_medium])\n",
    "    if (int(sql_count_targets[1][i])*3) > 2000:\n",
    "        feature_select = \"\\n,\".join([\"{feature}\".format(feature=f) for f in feature_list_large])\n",
    "    dv_item = DV_LIST[i]\n",
    "    random_sample = sample_share[i]\n",
    "    training_sql = f\"\"\"DROP VIEW IF EXISTS {SCHEMA}.{PREFIX}_training_{i} CASCADE;\n",
    "    CREATE VIEW {SCHEMA}.{PREFIX}_training_{i} AS \n",
    "    (select * from (\n",
    "    (select {PRIMARY_KEY}, {dv_item} from {DV_TABLE} where {dv_item} = 1) \n",
    "    union all \n",
    "    (select {PRIMARY_KEY}, {dv_item} from {DV_TABLE} where {dv_item} = 0 and random() < {random_sample}))\n",
    "    left join\n",
    "    (select {PRIMARY_KEY}, {feature_select} from {MODELING_FRAME}) using({PRIMARY_KEY}));\"\"\"\n",
    "    create_training_sql = civis.io.query_civis(training_sql, database=DATABASE)\n",
    "    create_training_sql.result().state\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING >>> spoke_support_1box\n",
      "TRAINING >>> spoke_persuasion_1plus\n",
      "TRAINING >>> spoke_persuasion_1minus\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "train_list = []\n",
    "model_list = []\n",
    "\n",
    "for index, dv in enumerate(DV_LIST):\n",
    "    print('TRAINING >>> {}'.format(dv))\n",
    "    \n",
    "    exc_list = DV_LIST.copy()\n",
    "    exc_list.remove(dv)\n",
    "    \n",
    "    assert dv not in exc_list \n",
    "    \n",
    "    name = f\"\"\"{dv}_{datestamp}\"\"\"\n",
    "    model = ModelPipeline(model='sparse_logistic',\n",
    "                          dependent_variable=dv,\n",
    "                          primary_key=PRIMARY_KEY,\n",
    "                          excluded_columns=EXCLUSION_COLUMNS,\n",
    "                          calibration='sigmoid',\n",
    "                          model_name=name,\n",
    "                          memory_requested=12000)\n",
    "    \n",
    "    where_string = '{} is not null'.format(dv)\n",
    "\n",
    "    train = model.train(table_name=f\"\"\"{SCHEMA}.{PREFIX}_training_{index}\"\"\", \n",
    "                        database_name=DATABASE,\n",
    "                        sql_where=where_string#,\n",
    "                        #fit_params={'sample_weight': WEIGHT_VAR}\n",
    "                       )\n",
    "    \n",
    "    model_list.append(model)\n",
    "    train_list.append(train)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job success\n",
      "Job success\n",
      "Job success\n"
     ]
    }
   ],
   "source": [
    "# Extract successful models\n",
    "model_output = model_list\n",
    "train_output = train_list\n",
    "\n",
    "jobs_list = []\n",
    "for t in train_output: \n",
    "    try:\n",
    "        if len(t.metadata['output']) > 0:  \n",
    "            jobs_list.append(t)\n",
    "            print('Job success')\n",
    "    except:\n",
    "        print('Job failure')\n",
    "        pass\n",
    "\n",
    "    \n",
    "model_output, train_output = zip(*((m, t) for m, t in zip(model_output, train_output) if t in jobs_list))\n",
    "model_output = list(model_output)\n",
    "train_output = list(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>dv</th>\n",
       "      <th>model</th>\n",
       "      <th>time_of_train_run</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_features</th>\n",
       "      <th>auc</th>\n",
       "      <th>deciles</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>p_correct</th>\n",
       "      <th>pop_incidence_true</th>\n",
       "      <th>feature_list</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192164893</th>\n",
       "      <td>53246690</td>\n",
       "      <td>spoke_support_1box</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-18T15:51:32Z</td>\n",
       "      <td>162815</td>\n",
       "      <td>466</td>\n",
       "      <td>0.757561</td>\n",
       "      <td>[0.056504114973590466, 0.10349487132240034, 0....</td>\n",
       "      <td>[[93206, 15300], [30502, 23807]]</td>\n",
       "      <td>0.718687</td>\n",
       "      <td>[0.8589939726835383, 0.43836196578835923]</td>\n",
       "      <td>[0.6664373675644136, 0.3335626324355864]</td>\n",
       "      <td>[civis_2020_partisanship, civis_2018_gotv, civ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192164898</th>\n",
       "      <td>53246693</td>\n",
       "      <td>spoke_persuasion_1plus</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-18T15:46:27Z</td>\n",
       "      <td>9140</td>\n",
       "      <td>466</td>\n",
       "      <td>0.624680</td>\n",
       "      <td>[0.16849015317286653, 0.21663019693654267, 0.2...</td>\n",
       "      <td>[[5729, 319], [2803, 289]]</td>\n",
       "      <td>0.658425</td>\n",
       "      <td>[0.947255291005291, 0.09346701164294954]</td>\n",
       "      <td>[0.661706783369803, 0.33829321663019696]</td>\n",
       "      <td>[civis_2020_ideology_liberal, civis_2018_gotv,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192164906</th>\n",
       "      <td>53246698</td>\n",
       "      <td>spoke_persuasion_1minus</td>\n",
       "      <td>sparse_logistic</td>\n",
       "      <td>2019-12-18T15:46:07Z</td>\n",
       "      <td>2643</td>\n",
       "      <td>466</td>\n",
       "      <td>0.722716</td>\n",
       "      <td>[0.11363636363636363, 0.09433962264150944, 0.1...</td>\n",
       "      <td>[[1631, 160], [603, 249]]</td>\n",
       "      <td>0.711313</td>\n",
       "      <td>[0.9106644332774986, 0.29225352112676056]</td>\n",
       "      <td>[0.677639046538025, 0.322360953461975]</td>\n",
       "      <td>[civis_2020_partisanship, civis_2020_race_whit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id                       dv            model  \\\n",
       "run_id                                                          \n",
       "192164893  53246690       spoke_support_1box  sparse_logistic   \n",
       "192164898  53246693   spoke_persuasion_1plus  sparse_logistic   \n",
       "192164906  53246698  spoke_persuasion_1minus  sparse_logistic   \n",
       "\n",
       "              time_of_train_run  n_rows  n_features       auc  \\\n",
       "run_id                                                          \n",
       "192164893  2019-12-18T15:51:32Z  162815         466  0.757561   \n",
       "192164898  2019-12-18T15:46:27Z    9140         466  0.624680   \n",
       "192164906  2019-12-18T15:46:07Z    2643         466  0.722716   \n",
       "\n",
       "                                                     deciles  \\\n",
       "run_id                                                         \n",
       "192164893  [0.056504114973590466, 0.10349487132240034, 0....   \n",
       "192164898  [0.16849015317286653, 0.21663019693654267, 0.2...   \n",
       "192164906  [0.11363636363636363, 0.09433962264150944, 0.1...   \n",
       "\n",
       "                           confusion_matrix  accuracy  \\\n",
       "run_id                                                  \n",
       "192164893  [[93206, 15300], [30502, 23807]]  0.718687   \n",
       "192164898        [[5729, 319], [2803, 289]]  0.658425   \n",
       "192164906         [[1631, 160], [603, 249]]  0.711313   \n",
       "\n",
       "                                           p_correct  \\\n",
       "run_id                                                 \n",
       "192164893  [0.8589939726835383, 0.43836196578835923]   \n",
       "192164898   [0.947255291005291, 0.09346701164294954]   \n",
       "192164906  [0.9106644332774986, 0.29225352112676056]   \n",
       "\n",
       "                                 pop_incidence_true  \\\n",
       "run_id                                                \n",
       "192164893  [0.6664373675644136, 0.3335626324355864]   \n",
       "192164898  [0.661706783369803, 0.33829321663019696]   \n",
       "192164906    [0.677639046538025, 0.322360953461975]   \n",
       "\n",
       "                                                feature_list  \n",
       "run_id                                                        \n",
       "192164893  [civis_2020_partisanship, civis_2018_gotv, civ...  \n",
       "192164898  [civis_2020_ideology_liberal, civis_2018_gotv,...  \n",
       "192164906  [civis_2020_partisanship, civis_2020_race_whit...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate validation metrics\n",
    "metrics_list = []\n",
    "\n",
    "for a, b in enumerate(train_output):\n",
    "    metric = {'job_id':b.job_id,\n",
    "              'run_id':b.run_id,\n",
    "              'dv': ''.join(b.metadata['run']['configuration']['data']['y']),\n",
    "              'model': b.metadata['model']['model'],\n",
    "              'time_of_train_run': b.metadata['run']['time_of_run'],\n",
    "              'n_rows': b.metadata['data']['n_rows'],\n",
    "              'n_features': b.metadata['data']['n_cols'],\n",
    "              'auc': b.metadata['metrics']['roc_auc'],\n",
    "              'deciles': b.metadata['metrics']['deciles'],\n",
    "              'confusion_matrix': b.metadata['metrics']['confusion_matrix'],\n",
    "              'accuracy': b.metadata['metrics']['accuracy'],\n",
    "              'p_correct': b.metadata['metrics']['p_correct'],\n",
    "              'pop_incidence_true': b.metadata['metrics']['pop_incidence_true'],\n",
    "              'feature_list':b.metadata['model']['parameters']['relvars']\n",
    "             }\n",
    "    metrics_list.append(metric)\n",
    "    \n",
    "metric_order = (['job_id', 'run_id', 'dv', 'model', 'time_of_train_run', 'n_rows', 'n_features',\n",
    "                 'auc', 'deciles', 'confusion_matrix', 'accuracy', 'p_correct','pop_incidence_true','feature_list'])\n",
    "\n",
    "validation_df = pd.DataFrame.from_records(metrics_list, columns=metric_order, index='run_id')\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write validation metrics to Redshift\n",
    "create_validation_table = civis.io.dataframe_to_civis(df=validation_df,\n",
    "                                                 database=DATABASE, \n",
    "                                                 table= f'{SCHEMA}.{PREFIX}_validation_{datestamp}', \n",
    "                                                 existing_table_rows='drop')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spoke_support_1box\n",
      "spoke_persuasion_1plus\n",
      "spoke_persuasion_1minus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'container_id': 53249078,\n",
       " 'error': None,\n",
       " 'finished_at': '2019-12-18T18:20:12.000Z',\n",
       " 'id': 192169675,\n",
       " 'is_cancel_requested': False,\n",
       " 'started_at': '2019-12-18T15:57:17.000Z',\n",
       " 'state': 'succeeded'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the voterfile\n",
    "scores_list = []\n",
    "for m,t in zip(model_output, train_output):\n",
    "    DV_NAME = ''.join(t.metadata['run']['configuration']['data']['y'])\n",
    "    print(DV_NAME)\n",
    "    SCORES_TABLE = f'{SCHEMA}.{PREFIX}_{DV_NAME}_{datestamp}'\n",
    "    scores_list.append(SCORES_TABLE)\n",
    "    scores = m.predict(primary_key=PRIMARY_KEY,\n",
    "                       database_name=DATABASE, \n",
    "                       table_name=MODELING_FRAME,\n",
    "                       if_exists='drop',\n",
    "                       output_table=SCORES_TABLE,\n",
    "                       disk_space=20)\n",
    "scores.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SQL for final output table and drop intermediary tables\n",
    "view_list = []\n",
    "table_list = []\n",
    "for i in range(len(DV_LIST)):\n",
    "    view = f\"{SCHEMA}.{PREFIX}_training_{i}\"\n",
    "    view_list.append(view)\n",
    "    table = f\"{SCHEMA}.{PREFIX}_{DV_LIST[i]}_{datestamp}\"\n",
    "    table_list.append(table)\n",
    "\n",
    "drop_view_sql = \"\\n\".join([\"drop view if exists {view} CASCADE;\".format(view=v) for v in view_list])\n",
    "drop_table_sql = \"\\n\".join([\"drop table if exists {tbl};\".format(tbl=t) for t in table_list])  \n",
    "dv_strings = \"\\n,\".join([\"{dv_score}_1 as {dv_score}\".format(dv_score=dv) for dv in DV_LIST])\n",
    "dv_tiles = \"\\n,\".join([\"NTILE(100) OVER (ORDER BY {dv_tile}_1) AS {dv_tile}_100\".format(dv_tile=dv) for dv in DV_LIST])\n",
    "join_table = []\n",
    "if len(table_list) > 1:\n",
    "    for i in table_list[1:]:\n",
    "        j = str(' left join '+f'{i}'+f' using({PRIMARY_KEY}) ')\n",
    "        join_table.append(j)\n",
    "        #dv_strings = \"\\nleft join \".join([\"{dv_score}\".format(table=tbl) for tbl in table_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table_sql = f\"\"\"DROP TABLE IF EXISTS {SCHEMA}.{PREFIX}_output_{datestamp};\n",
    "CREATE TABLE {SCHEMA}.{PREFIX}_output_{datestamp}\n",
    "  DISTSTYLE KEY\n",
    "  DISTKEY ({PRIMARY_KEY})\n",
    "  SORTKEY ({PRIMARY_KEY})\n",
    "  AS (\"\"\"+'select '+ f\"{PRIMARY_KEY} \\n,\" + dv_strings + \"\\n,\" + dv_tiles + ' from '+ ''.join(table_list[0]) + ''.join(join_table) +');'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS bernie_nmarchio2.scored_output_20191218;\n",
      "CREATE TABLE bernie_nmarchio2.scored_output_20191218\n",
      "  DISTSTYLE KEY\n",
      "  DISTKEY (person_id)\n",
      "  SORTKEY (person_id)\n",
      "  AS (select person_id \n",
      ",spoke_support_1box_1 as spoke_support_1box\n",
      ",spoke_persuasion_1plus_1 as spoke_persuasion_1plus\n",
      ",spoke_persuasion_1minus_1 as spoke_persuasion_1minus\n",
      ",NTILE(100) OVER (ORDER BY spoke_support_1box_1) AS spoke_support_1box_100\n",
      ",NTILE(100) OVER (ORDER BY spoke_persuasion_1plus_1) AS spoke_persuasion_1plus_100\n",
      ",NTILE(100) OVER (ORDER BY spoke_persuasion_1minus_1) AS spoke_persuasion_1minus_100 from bernie_nmarchio2.scored_spoke_support_1box_20191218 left join bernie_nmarchio2.scored_spoke_persuasion_1plus_20191218 using(person_id)  left join bernie_nmarchio2.scored_spoke_persuasion_1minus_20191218 using(person_id) );\n"
     ]
    }
   ],
   "source": [
    "print(output_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final output table\n",
    "create_output_table = civis.io.query_civis(sql=output_table_sql, database=DATABASE)\n",
    "create_output_table.result().state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop intermediary tables\n",
    "drop_views_query = civis.io.query_civis(sql=drop_view_sql, database=DATABASE)\n",
    "drop_views_query.result().state\n",
    "\n",
    "drop_tables_query = civis.io.query_civis(sql=drop_table_sql, database=DATABASE)\n",
    "drop_tables_query.result().state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop view if exists bernie_nmarchio2.scored_training_0 CASCADE;\n",
      "drop view if exists bernie_nmarchio2.scored_training_1 CASCADE;\n",
      "drop view if exists bernie_nmarchio2.scored_training_2 CASCADE;\n",
      "drop table if exists bernie_nmarchio2.scored_spoke_support_1box_20191218;\n",
      "drop table if exists bernie_nmarchio2.scored_spoke_persuasion_1plus_20191218;\n",
      "drop table if exists bernie_nmarchio2.scored_spoke_persuasion_1minus_20191218;\n"
     ]
    }
   ],
   "source": [
    "print(drop_view_sql)\n",
    "print(drop_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'succeeded'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grant team on tables\n",
    "grant_statement = f\"\"\"\n",
    "GRANT ALL ON SCHEMA {SCHEMA} TO GROUP bernie_data;\n",
    "GRANT SELECT ON {SCHEMA}.{PREFIX}_output_{datestamp} TO GROUP bernie_data;\n",
    "\"\"\"\n",
    "grant_team = civis.io.query_civis(sql=grant_statement, database=DATABASE)\n",
    "grant_team.result().state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GRANT ALL ON SCHEMA bernie_nmarchio2 TO GROUP bernie_data;\n",
      "GRANT SELECT ON bernie_nmarchio2.scored_output_20191218 TO GROUP bernie_data;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grant_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
